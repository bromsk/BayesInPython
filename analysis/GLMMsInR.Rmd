---
title: "GLMMs in R"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  bookdown::html_document2:
    fig_caption: yes
    fig_height: 4
    fig_width: 6
    highlight: tango
    number_sections: yes
    theme: cerulean
    toc: yes
    toc_float: true
    code_folding: hide
editor_options:
  chunk_output_type: console
---

```{r setwd, eval = F, echo = F}
setwd("analysis")
```
```{r setup, include=FALSE, message=F, warning=FALSE, results = "hide", echo=F}
knitr::opts_chunk$set(cache = T, message =F, warning = F, echo=F,
                      # dpi = 36, out.width="600px", out.height="600px")
  fig.width = 8,
  fig.height = 5,
  out.width = '100%')

# R libraries:
library(MASS)
library(lme4)
library(magrittr)
library(tidyverse)
library(ggmap)
# usethis::edit_r_environ()
register_google(Sys.getenv("ggmapKey"))

## Set colors:
# library(RColorBrewer)
# display.brewer.pal(11, "Spectral")
# brewer.pal(11, "Spectral")
mycolors =  c("#9E0142", "#762A83","#9970AB",  # "#5E4FA2",
              "#3288BD","#66C2A5", "#ABDDA4", "#D53E4F")
visualcols = c( "#D7191C", "#FDAE61", "#FFFFBF", "#A6D96A", "#1A9641")
trialcols = c("#4575B4", "#40004B","#762A83","#9970AB",  "#5AAE61",
               "#C2A5CF","#74ADD1", "#E7D4E8", "#ABD9E9",   "#00441B" )
prop_colors = c("#313695", "#ABD9E9", "#FFFFBF", "#FEE090", 
                 "#FDAE61", "#F46D43","#D73027", "#A50026")
#
```
``` {r functions}

getDR <- function (mod, coefs = -1) {
  b1 = summary(mod)$coef[coefs,1]
  seb1 = summary(mod)$coef[coefs,2]
  (DR = round(100 * (1- exp(b1)),1))  ## 69.9
  (higher = round(100 * (1 - exp(b1 - 1.96*seb1)),1)) ## 78.8
  (lower = round(100 * (1 - exp(b1 + 1.96*seb1)),1)) ## 57.0
  if (is.null(names(DR))) {
   data.frame(#Treatment = names(DR),
             DR = as.numeric(DR), 
             lowerCI = as.numeric(lower),
             upperCI = as.numeric(higher))   
  } else {
  data.frame(Treatment = names(DR),
             DR = as.numeric(DR), 
             lowerCI = as.numeric(lower),
             upperCI = as.numeric(higher))
  }
}

## NA = 0 in sum
`%+%` <- function(x, y)  mapply(sum, x, y, MoreArgs = list(na.rm = TRUE))
#


```
```{r readdatR}

moddatR = read.csv("../data/mothsubset.csv")
moddatR %<>%
  mutate(TransplantDate = ymd(TransplantDate),
         DispInstallDate = ymd(DispInstallDate),
         TrapInstallDate = ymd(TrapInstallDate),
         SamplingDate = ymd(SamplingDate)
         )
```

# Introduction

I have used R, in conjunction with Rmarkdown documents, in an RStudio GUI for over a decade. It is a beautiful setup, with great work flows and clean coding. It is perfect for non-production level analyses, visualizations, interactive documents and web apps, and reports.

However, the world seems to prefer Python. Perhaps it is because computer programmers rule the world more than statisticians and scientists.

So, in that vein, I am writing this tutorial to fit Bayesian GLMMs and non-linear regression models commonly in Python, Pyton’s Bambi module, and Python’s PyMC module.

The intended audience here is someone who is proficient at fitting statistical models in R, but would like to fit those same models in Python instead. In particular, fitting complex Bayesian hierarchical models.

I have two purposes:

1. To learn if I can fit complex non-linear Bayesian models with multi-dimensional Gaussian Processes in Python. I currently have custom algorithms written in Matlab for these models, and I want to fit the same models in Python.

2. To get better acquainted with Python.

All models are written mathematically and fit in both R and Python. Frequentist versions are fit when available as well as Bayesian versions.

## Outline


* Getting started with Python-- because it is more complicated than R.

* Introduce the data to be used throughout the tutorial.

* Fit generalized linear models (GLMs, here Poisson regressions).

* Fit generalized linear models with random effects (GLMMs).


# Data Exploration

We are analyzing moth count data collected from traps from rice fields in Indonesia. There are a total of 10 locations. At each location, there is one treatment (PFP) field with 4 traps and one control field with 4 traps. These traps are sampled and reset approximately every 10 days for the entire growing season, but sometimes that interval varies.

It is expected that the PFP will catch fewer moths than the control fields. The research questions are: how much fewer moths are caught, i.e., what is the trapping reduction associated with the PFP traps? and, is the same trapping reduction observed for the entire season?

These data have a spatial and temporal component. Temporally, the same traps are sampled over time. Spatially, the traps have a certain proximity to each other within a location, and the locations may be clumped across the landscape.

These data are based on the data from Iqbal et al. (2023) (link: https://jurnal.pei-pusat.org/index.php/jei/article/view/783), but have been heavily manipulated in terms of locations and counts to preserve privacy rights.

Full citation:
Iqbal, M., Marman, M., Arintya, F., Broms, K. ., Clark, T., & Srigiriraju, L. . (2023). Mating disruption technology: An innovative tool for managing yellow stem borer (Scirpophaga incertulas Walker) of rice in Indonesia: Teknologi gangguan kawin: Inovasi untuk pengendalian penggerek batang kuning (Scirpophaga incertulas Walker) pada padi di Indonesia. Jurnal Entomologi Indonesia, 20(2), 129. https://doi.org/10.5994/jei.20.2.129.

## Trap locations

(Because I am plotting coordinates, I set the aspect ratio to be 1, which creates square plots to better mimic the actual locations of the traps.)

Treatment traps have a slightly different alignment at each location:

```{r}

ggplot(moddatR) +
  geom_point(aes(Longitude, Latitude, color = Details)) +
  facet_wrap(~Location, scales = "free") +
  theme(aspect.ratio=1, x.axis = F)

```

Trial locations in relation to each other. Some trial locations are closer to each other than others.

```{r}

basemap <- get_googlemap(c(lon = mean(moddatR$Longitude, na.rm = T),
                           lat = mean(moddatR$Latitude, na.rm = T)),
                         color = "bw",
                         zoom = 4)
ggmap(basemap) +
  geom_point(data = moddatR,
             aes(Longitude, Latitude, color = Location), size = 2) +
  labs(title = "Trial locations") +
  scale_color_brewer(palette = "PuOr") 

```


## Timeline

```{r timeline, results="hide", fig.width = 7}

dates <- moddatR %>%
  group_by(Location, TransplantDate, TrapInstallDate) %>%
  summarize(mindate = min(SamplingDate, na.rm = T),
            maxdate = max(SamplingDate, na.rm = T)) %>%
  ungroup() %>%
  arrange(desc(mindate), Location)
dates$Location <- factor(dates$Location, levels = unique(dates$Location))

ggplot(dates) +
  geom_errorbarh(aes(xmin = mindate, xmax = maxdate, 
                     y = Location, color = Location),
                 height = 0.5, linewidth = 1.25) +
  geom_jitter(aes(TransplantDate, y = Location), width = 0, height = 0.1, size = 1.25) +
  geom_jitter(aes(TrapInstallDate, y = Location), width = 0, height = 0.1, 
              size = 1.25, color = gray(0.6)) +
  labs(y = "Location",
       x = "Date range of moths data collection (2023)",
       title = "Trapping date ranges of each location",
       caption = "Black points are transplant dates \n
       Grey points are installation dates") +
  scale_color_viridis_d() 
```


## Moth counts

```{r plotMoths, fig.width = 8, fig.height = 6}
mean_cts <- moddatR %>%
  group_by(Location, Treatment, Details,
           AssessmentNumber,
           SamplingDate, DATI) %>%
  summarize(mean_cts = mean(nYSB, na.rm = T),
            mean_mothsperday = mean(mothsperday)) %>%
  ungroup()
ggplot(moddatR,
       aes(DATI, mothsperday, color = Details)) +
  geom_jitter(height = 0, width = 0.75, alpha = 0.5) +
  # geom_line(data = mean_cts,
      # aes(DATI, mean_mothsperday, color = Details), size = 1.1) +
  geom_smooth(se=F) +
  facet_wrap(~Location, scales = "free_y") + 
  scale_color_manual(values = mycolors[]) +
  # scale_color_viridis_d() +
  # scale_y_sqrt() +
  labs(title = "Male YSB moth counts for each location and trap",
       y = "Moth counts per trap per day",
       x = "DAI",
       color = "Treatment")
#
```

# Basic GLM models

To start, we ignore all the spatial and temporal relations and assume each data point is independent and identically distributed (iid). **This is not a good model for the data!** It is just our starting off point.

These models are known as generalize linear models (GLMs).

## Mathematical model

We start with a poisson version of our regression model:

$$
y_i \sim Pois(\lambda_i) \\
log(\lambda_i ) = \beta_0 + \beta_1 x_{A,i} + \mbox{ln} \left(DaysOfCatch_i\right)
$$

where

$y_i$ is moth count $i$,

$\lambda_i$ is the expected moth count for sample $i$,

$\beta_0$ is the intercept of the model. Here, it is the basis for the expected moth count for our control treatment.

$\beta_1$ is the expected difference in moth counts between the control group and the 'trt A' group, 

$x_{A,i}$ is an indicator variable that equals 1 if sample $i$ is from a "trt A" field and equals 0 otherwise, and

$\left(DaysOfCatch_i\right)$ is the offset to account for the varying time itnerval between samples. This is necessary because with a longer time interval, more moths will fly into the trap.

However, in ecology, there is always additional variability in our data than what the Poisson distribution allows. To account for the additional variability in our model, we switch to a negative binomial distribution:

$$
y_i \sim NegBinom(\lambda_i, \phi) \\
log(\lambda_i ) = \beta_0 + \beta_1 x_{A,i} + \mbox{ln} \left(DaysOfCatch_i\right)
$$

"Negative binomial regression is used to model count data for which the variance is higher than the mean." (https://www.pymc.io/projects/examples/en/latest/generalized_linear_models/GLM-negative-binomial-regression.html)

For the negative binomial regression, all variables and parameters are defined as before, but the model has an additional parameter, $\phi$, that allows for the additional variation. The negative binomial distribution and regression model can be written in many ways. In our models, $\phi$ is defined through the following formula where the variance associated with an expected moth count, $\lambda$, is:

$$
Var(\lambda) = \lambda + \phi \cdot\lambda^2
$$

(For a Poisson distribution, $Var(\lambda) = \lambda$.)

### Bayesian regression models

I also fit these models uing a Bayesian framework, again to build our foundation for our more complex models that come later.

For the Bayesian models, I only show the more complex negative binomial version.

To make our models Bayesian, we add priors to our parameters:

$$
y_i \sim NegBinom(\lambda_i, \phi) \\
log(\lambda_i ) = \beta_0 + \beta_1 x_{i} + \mbox{ln} \left(DaysOfCatch_i\right) \\
\beta_0 \sim Normal(0, 2) \\
\beta_1 \sim Normal(0, 2) \\
\phi \sim HalfCauchy(0,1)
$$

The models use slightly informative priors. When working on a log-scale (e.g., with Poisson or negative binomial distributions), this often becomes essential to avoid parameter estimates on the boundaries. (See Hooten and Hobbs for a good discussion on this issue.)

### Trapping reduction defined

The primary metric of interest from these models is a derived parameter that we call trapping reduction (TR):

$$
TR = 100 - 100 e ^{(-\beta_1)}
$$

To obtain a 95% confidence interval for TR (for the frequentist version of our model), we use the following approximation:

$$
TR = 100 - 100 e ^{(-\beta_1 \pm 2 \cdot SE(\beta_1))}
$$


## Frequentist models

Note: when I predict for new data, I set DaysOfCatch = 1, and then I compare to the moths per day variable (mothsperday = nYSB / DaysOfCatch). I want to exclude any patterns related to the varying time intervals.

```{r pois1}

mod1p <- glm(nYSB ~ DetailsF, 
             offset = log(DaysOfCatch),
             family = poisson,
             data = moddatR)
summary(mod1p)
getDR(mod1p)
tmp = predict(mod1p, se = T, link = F,
              newdata= moddatR  %>% mutate(DaysOfCatch = 7))
# str(tmp)
preds1p <- data.frame(moddatR, 
                      preds = tmp$fit,
                      lowerCI = tmp$fit + 2*tmp$se.fit,
                      upperCI = tmp$fit - 2*tmp$se.fit)
# preds1p %<>%
#   mutate(preds = exp(preds),
#          lowerCI = exp(lowerCI),
#          upperCI = exp(upperCI))
# str(preds1p)

ggplot(preds1p,
       aes(DATI, preds, color = DetailsF)) +
  geom_ribbon(aes(ymin = lowerCI, ymax = upperCI, fill = DetailsF),
              alpha = 0.3) + 
  geom_jitter(height = 0, width = 0.75, alpha = 0.5) +
  # geom_line(data = mean_cts,
      # aes(DATI, mean_mothsperday, color = Details), size = 1.1) +
  geom_smooth(se=F) +
  facet_wrap(~Location, scales = "free_y") + 
  scale_color_manual(values = mycolors[]) +
  scale_fill_manual(values = mycolors[]) 

  
```
```{r nb1}

mod1nb <- glm.nb(nYSB ~ DetailsF + 
             offset(log(DaysOfCatch)),
             data = moddatR)
summary(mod1nb)
getDR(mod1nb)
tmp = predict(mod1nb, se = T, link = T,
              newdata= moddatR  %>% mutate(DaysOfCatch = 1))
# str(tmp)
preds1nb <- data.frame(moddatR, 
                      preds = tmp$fit,
                      lowerCI = tmp$fit - 2*tmp$se.fit,
                      upperCI = tmp$fit + 2*tmp$se.fit)
preds1nb %<>%
  mutate(preds = exp(preds),
         lowerCI = exp(lowerCI),
         upperCI = exp(upperCI))
# str(preds1nb)

ggplot(preds1nb,
       aes(DATI, preds, color = DetailsF)) +
  geom_ribbon(aes(ymin = lowerCI, ymax = upperCI, fill = DetailsF),
              alpha = 0.3) + 
  geom_jitter(height = 0, width = 0.75, alpha = 0.5) +
  geom_point(
      aes(DATI, mothsperday, color = DetailsF), size = 1.1) +
  geom_smooth(se=F) +
  facet_wrap(~Location, scales = "free_y") + 
  scale_color_manual(values = mycolors[]) +
  scale_fill_manual(values = mycolors[]) 

  
```

## Bayesian (brms) models

In R, I fit the Bayesian models using the "brms" package. I find this package very intuitive and it has fast, efficient algorithms based on Stan.

The prior_summary command is helpful if you so not know what a parameter is called in 'brms'. Here, I used the command to find out what they called their $\phi$ parameter, and then I re-ran the model with my slightly informative prior.

```{r}
library(brms)
nCores = 6 # nCores -2
# 

brm1nb <- brm(formula = nYSB ~ DetailsF + offset(logDaysOfCatch),
              data = moddatR, 
              family = negbinomial, #log-link is default
              prior = c(set_prior("normal(0,2)", class = "b"),
                        set_prior("normal(0,2)", class = "Intercept"),
                        set_prior("cauchy(0,1)", class = "shape")),
              warmup = 500, iter = 2000, 
              chains = nCores, cores = nCores) 
saveRDS(brm1nb, "../output/brm1nb.RDS")
summary(brm1nb)
bayes_R2(brm1nb)

prior_summary(brm1nb)
# 
```

# GLMM: Random effect for location

The first fix we make to the model is acknowledging that overall average  moth pressure varies from location to location. To make this fix we had a location random effect (RE) and our model becomes a generalized linear mixed-effects model (GLMM or GLMER).

We also want to acknowledge that the treatment effect may vary from location to location-- sometimes we see a big different in moth counts between control and treatment fields, and sometimes the difference is smaller. For inference though, we are only interested in the larger picture, which is the overall trapping reduction. Therefore, we also add a treatment random effect.

## GLMM mathematical model

I only show the Poisson version of the model, the NB version is a straightforward extension.

$$
y_{ik} \sim Pois(\lambda_{ik}) \\
log(\lambda_{ik} ) = \beta_0 + \beta_1 x_{A,i} + \gamma_{0k} x_{ik}  + \gamma_{1k} x_{A,i} x_{ik} + \mbox{ln} \left(DaysOfCatch_i\right) \\
\gamma_{0k} \sim Normal(0, \sigma^2_{0}) \\
\gamma_{1k} \sim Normal(0, \sigma^2_{1}) \\
$$

where,in addition to the variables and parameters defined for the GLM, we have

$y_{ik}$ is moth count $i$ from location $k$,

$\lambda_{ik}$ is the expected moth count for sample $i$  from location $k$,

$\beta_0$ is the expected moth count for our control treatment for a new location,

$\beta_1$ is the expected difference in moth counts between the control group and the 'trt A' group for a new location, 

$\gamma_{0k}$ is the random intercept associated with location $k$, which leads to different background moth pressures at each location. All $\gamma_{0k}$ come from an iid Normal distribution.

$\gamma_{1k}$ is the random slope associated with location $k$, which leads to different treatment effects at each location. All $\gamma_{1k}$ come from an iid Normal distribution, and

$x_{ik}$ is an indicator variable that equals 1 if moth count $i$ is associated with location $k$ and 0 otherwise.

OK, technically I should be introducing matrices here because $k = 1,..., 10$ locations, so we need a new indicator variable for each location, but I'm going to be lazy and right it like this for now.

$\left(DaysOfCatch_i\right)$ is the offset to account for the varying time itnerval between samples. This is necessary because with a longer time interval, more moths will fly into the trap.


### Bayesian GLMM

Here is the same model with a Bayesian framework and using a negative binomial regression:

To make our models Bayesian, we add priors to our parameters:

$$
y_{ik}\sim NegBinom(\lambda_{ik}, \phi) \\
log(\lambda_{ik} ) = \beta_0 + \beta_1 x_{A,i} + \gamma_{0k} x_{ik}  + \gamma_{1k} x_{A,i} x_{ik} + \mbox{ln} \left(DaysOfCatch_i\right) \\
\gamma_{0k} \sim Normal(0, \sigma^2_{0}) \\
\gamma_{1k} \sim Normal(0, \sigma^2_{1}) \\

\beta_0 \sim Normal(0, 2) \\
\beta_1 \sim Normal(0, 2) \\
\sigma^2_{0} \sim HalfCauchy(0,1) \\
\sigma^2_{1} \sim HalfCauchy(0,1) \\
\phi \sim HalfCauchy(0,1)
$$

### Bayesian GLMM -- Matrix version

Written in matrix form, which better matches the coding (and is more correct given the need for a 10x10 $Z$ desgin matrix):

$$
\mathbf{Y} \sim NegBinom(\boldsymbol\lambda, \phi) \\
log(\boldsymbol\lambda) = \mathbf{X}\boldsymbol\beta + \mathbf{Z}\boldsymbol\gamma  + \mbox{ln} \left(\bf{DaysOfCatch}\right) \\
\boldsymbol\beta \sim Normal(\mathbf{0}, 2\mathbf{I}) \\
\boldsymbol\gamma \sim Normal(\mathbf{0}, \boldsymbol\sigma^2 \mathbf{I}) \\
\boldsymbol\sigma^2 \sim HalfCauchy(\mathbf{0}, 1\mathbf{I})) \\
\phi \sim HalfCauchy(0,1)
$$


## GLMM frequentist version

A couple of notes here. R always gets mad when you ask for SE's for predictions from a GLMM. Technically, you need to run simulations to get them and then they still come with an asterisk related to their reliability. (This is a reason to use the Bayesian model-- credible intervals are never based on apprioximations!)

When we plot our predictions, we see that we now have better estimates for the overall mean at each location, and we see how much they vary from location to location, but there is a strong temporal pattern at each location that we are missing.

```{r pois2}
modp2 <- glmer(nYSB ~ DetailsF + (1 + DetailsF|Location), 
             offset = log(DaysOfCatch),
             family = poisson,
             data = moddatR)
summary(modp2)
getDR(modp2)
tmp = predict(modp2, se = T, 
              newdata=moddatR %>% mutate(DaysOfCatch = 1))
# str(tmp)
predsp2 <- data.frame(moddatR %>% mutate(DaysOfCatch = 1), 
                      preds = tmp$fit,
                      lowerCI = tmp$fit + 2*tmp$se.fit,
                      upperCI = tmp$fit - 2*tmp$se.fit)
predsp2 %<>%
  mutate(preds = exp(preds),
         lowerCI = exp(lowerCI),
         upperCI = exp(upperCI))
# str(predsp2)
ggplot(predsp2,
       aes(DATI, preds, color = DetailsF)) +
  geom_ribbon(aes(ymin = lowerCI, ymax = upperCI, fill = DetailsF),
              alpha = 0.3) + 
  # geom_jitter(height = 0, width = 0.75, alpha = 0.5) +
  geom_point(aes(DATI, mothsperday, color = DetailsF), size = 1.1) +
  # geom_smooth(se=F) +
  facet_wrap(~Location, scales = "free_y") + 
  scale_color_manual(values = mycolors[]) +
  scale_fill_manual(values = mycolors[]) 

```
```{r nb2}
modnb2 <- glmer.nb(nYSB ~ DetailsF + (1 + DetailsF|Location), 
             offset = log(DaysOfCatch),
             data = moddatR)
summary(modnb2)
getDR(modnb2)
tmp = predict(modnb2, se = T, 
              newdata=moddatR %>% mutate(DaysOfCatch = 1))
# str(tmp)
predsnb2 <- data.frame(moddatR, 
                      preds = tmp$fit,
                      lowerCI = tmp$fit + 2*tmp$se.fit,
                      upperCI = tmp$fit - 2*tmp$se.fit)
predsnb2 %<>%
  mutate(preds = exp(preds),
         lowerCI = exp(lowerCI),
         upperCI = exp(upperCI))
# str(predsnb2)
ggplot(predsnb2,
       aes(DATI, preds, color = DetailsF)) +
  geom_ribbon(aes(ymin = lowerCI, ymax = upperCI, fill = DetailsF),
              alpha = 0.3) + 
  # geom_jitter(height = 0, width = 0.75, alpha = 0.5) +
  geom_point(aes(DATI, mothsperday, color = DetailsF), size = 1.1) +
  geom_smooth(se=F) +
  facet_wrap(~Location, scales = "free_y") + 
  scale_color_manual(values = mycolors[]) +
  scale_fill_manual(values = mycolors[]) 

```


## GLMM Bayes (brms) version

By default, the prior distributions of random slopes and intercepts are correlated in "brm". The first time I ran this model, I allowed them to be correlated, but their correlation was highly nonsignificant, so I changed the random effects term from "(1 + DetailsF|Location)" to " (1 + DetailsF||Location)" (has an extra vertical line), which makes them independent and matches our models from R more readily. However, you'll notice that the estimates are slightly different-- the more complicated your model is, the more liely you will fin dthis is true with slightly different versions of your model (here, adding priors and fitting with a different algorithm). 

```{r}
library(brms)
nCores = 6 # nCores -2
brm2nb <- brm(formula = nYSB ~ DetailsF + offset(logDaysOfCatch) + 
                    (1 + DetailsF||Location),
              data = moddatR, 
              family = negbinomial,
              prior = c(set_prior("normal(0,2)", class = "b"),
                        # below is == half-cauchy
                        set_prior("cauchy(0,1)", class = "shape"), 
                            set_prior("normal(0,2)", class = "Intercept"),
                            set_prior("cauchy(0,1)", class = "sd")),
              warmup = 500, iter = 2000, 
              chains = nCores, cores = nCores) 
saveRDS(brm2nb, "../output/brm2nb.RDS")
```
```{r}
summary(brm2nb)

# prior_summary(brm2nb)
# 
```



# RE for Trial, nested SamplingDate

## Frequentist version

```{r pois3, results = "hide", eval = F}
modp3 <- glmer(nYSB ~ DetailsF  +
                     (1+DetailsF|Village:SamplingDateC), 
             offset = log(DaysOfCatch),
             family = poisson,
             data = moddat)
summary(modp3)
getDR(modp3)
tmp = predict(modp3, se = T, link = T)
# str(tmp)
predsp3 <- data.frame(moddat, 
                      preds = tmp$fit,
                      lowerCI = tmp$fit + 2*tmp$se.fit,
                      upperCI = tmp$fit - 2*tmp$se.fit)
predsp3 %<>%
  mutate(preds = exp(preds),
         lowerCI = exp(lowerCI),
         upperCI = exp(upperCI))
# str(predsp3)
ggplot(predsp3,
       aes(DATI, preds, color = DetailsF)) +
  geom_ribbon(aes(ymin = lowerCI, ymax = upperCI, fill = DetailsF),
              alpha = 0.3) + 
  # geom_jitter(height = 0, width = 0.75, alpha = 0.5) +
  geom_point(aes(DATI, nYSB, color = DetailsF), size = 1.1) +
  geom_smooth(se=F) +
  facet_wrap(~Country + Region + Village, scales = "free_y") + 
  scale_color_manual(values = mycolors[]) +
  scale_fill_manual(values = mycolors[]) 

```
```{r nb3, results = "hide", eval = F}
# too slow!
# modnb3 <- glmer.nb(nYSB ~ DetailsF  +
#                      (1+DetailsF|Village:SamplingDateC), 
#              offset = log(DaysOfCatch),
#              # family = poisson,
#              data = moddat)
# summary(modnb3)
# getDR(modnb3)
# tmp = predict(modnb3, se = T, link = T)
# # str(tmp)
# predsnb3 <- data.frame(moddat, 
#                       preds = tmp$fit,
#                       lowerCI = tmp$fit + 2*tmp$se.fit,
#                       upperCI = tmp$fit - 2*tmp$se.fit)
# predsnb3 %<>%
#   mutate(preds = exp(preds),
#          lowerCI = exp(lowerCI),
#          upperCI = exp(upperCI))
# # str(predsnb2)
# ggplot(predsnb3,
#        aes(DATI, preds, color = DetailsF)) +
#   geom_ribbon(aes(ymin = lowerCI, ymax = upperCI, fill = DetailsF),
#               alpha = 0.3) + 
#   # geom_jitter(height = 0, width = 0.75, alpha = 0.5) +
#   geom_point(aes(DATI, nYSB, color = DetailsF), size = 1.1) +
#   geom_smooth(se=F) +
#   facet_wrap(~Country + Region + Village, scales = "free_y") + 
#   scale_color_manual(values = mycolors[]) +
#   scale_fill_manual(values = mycolors[]) 

```


## Bayes (brms) version

```{r}
library(brms)
nCores = 6 # nCores -2

# summary(moddat$numericDate) # check max before fitting
# brm3p <- brm(formula = nYSB ~ DetailsF + offset(logDaysOfCatch) + 
#                     (1 + DetailsF||TrialID:SamplingDateC),
#                     # gp(numericDate, by =TrialID), 
#                   # control = list(adapt_delta = 0.9),
#                   data = moddat, 
#              family = poisson,
#                   prior = c(set_prior("normal(0,2)", class = "b"),
#                             set_prior("normal(0,2)", class = "Intercept"),
#                             set_prior("cauchy(0,2)", class = "sd")),
#                             # set_prior("half-N(0,1)", class = "lscale"),
#                             # set_prior("normal(0,2)", class = "sdgp"),
#                             # set_prior("lkj(2)", class = "cor")),
#                   # sample_prior = TRUE,
#                   warmup = 500, iter = 2000, 
#                   chains = nCores, cores = nCores) 
# saveRDS(brm3p, "../output/brm3p.RDS")
# summary(brm3p)
# bayes_R2(brm3p) 
# 

brm3nb <- brm(formula = nYSB ~ DetailsF + offset(logDaysOfCatch) + 
                    (1 + DetailsF||Location:SamplingDateC),
              data = moddatR, 
              family = negbinomial,
              prior = c(set_prior("normal(0,2)", class = "b"),
                        set_prior("cauchy(0,1)", class = "shape"), # == half-cauchy
                            set_prior("normal(0,2)", class = "Intercept"),
                            set_prior("cauchy(0,2)", class = "sd")),
              warmup = 500, iter = 2000, 
              chains = nCores, cores = nCores) 
saveRDS(brm3nb, "../output/brm2nb.RDS")
summary(brm3nb)
bayes_R2(brm3nb)

prior_summary(brm3nb)
# prior_summary(brm3nb, all = FALSE)
# print(prior_summary(brm3nb, all = FALSE), show_df = FALSE)

# 
```

# RE for Trial, GP for Date

## Bayes (brms) version

```{r}
library(brms)
nCores = 6 # nCores -2

summary(moddatR$numericDate) # check max before fitting
brm4nb <- brm(formula = nYSB ~ DetailsF + offset(logDaysOfCatch) + 
                    (1 + DetailsF||Location) + 
              gp(numericDate, by =Location), 
                  # control = list(adapt_delta = 0.9),
              data = moddatR, 
              family = negbinomial,
              prior = c(set_prior("normal(0,2)", class = "b"),
                        set_prior("cauchy(0,1)", class = "shape"), # == half-cauchy
                            set_prior("normal(0,2)", class = "Intercept"),
                            set_prior("cauchy(0,2)", class = "sd")),
                            # set_prior("half-N(0,1)", class = "lscale"),
                            # set_prior("normal(0,2)", class = "sdgp"),
                            # set_prior("lkj(2)", class = "cor")),
              warmup = 500, iter = 2000, 
              chains = nCores, cores = nCores) 
saveRDS(brm4nb, "../output/brm2nb.RDS")
summary(brm4nb)
bayes_R2(brm4nb)

prior_summary(brm4nb)
# prior_summary(brm4nb, all = FALSE)
# print(prior_summary(brm4nb, all = FALSE), show_df = FALSE)

# 
```





